{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Spark library and functions\n",
    "import pyspark as ps\n",
    "import pyspark.sql.types as types\n",
    "from pyspark.sql.functions import col, countDistinct\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "# Sklearn Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Surprise modeling\n",
    "from surprise import SVD\n",
    "import surprise\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Persistance\n",
    "import pickle\n",
    "\n",
    "# Housekeeping\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_df = pd.read_json('review.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (ps.sql.SparkSession\n",
    "         .builder\n",
    "         .master('local[4]')\n",
    "         .appName('lecture')\n",
    "         .getOrCreate()\n",
    "        )\n",
    "# sc = spark.sparkContext\n",
    "\n",
    "review_df = spark.read.json(\"data/review.json\")\n",
    "# checkin_df = spark.read.json(\"data/checkin.json\")\n",
    "# tip_df = spark.read.json(\"data/tip.json\")\n",
    "# user_df = spark.read.json(\"data/user.json\")\n",
    "business_df = spark.read.json(\"data/business.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the content of the DataFrame to stdout\n",
    "# review_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tip_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# photo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(address='2818 E Camino Acequia Drive', attributes=Row(AcceptsInsurance=None, AgesAllowed=None, Alcohol=None, Ambience=None, BYOB=None, BYOBCorkage=None, BestNights=None, BikeParking=None, BusinessAcceptsBitcoin=None, BusinessAcceptsCreditCards=None, BusinessParking=None, ByAppointmentOnly=None, Caters=None, CoatCheck=None, Corkage=None, DietaryRestrictions=None, DogsAllowed=None, DriveThru=None, GoodForDancing=None, GoodForKids='False', GoodForMeal=None, HairSpecializesIn=None, HappyHour=None, HasTV=None, Music=None, NoiseLevel=None, Open24Hours=None, OutdoorSeating=None, RestaurantsAttire=None, RestaurantsCounterService=None, RestaurantsDelivery=None, RestaurantsGoodForGroups=None, RestaurantsPriceRange2=None, RestaurantsReservations=None, RestaurantsTableService=None, RestaurantsTakeOut=None, Smoking=None, WheelchairAccessible=None, WiFi=None), business_id='1SWheh84yJXfytovILXOAQ', categories='Golf, Active Life', city='Phoenix', hours=None, is_open=0, latitude=33.5221425, longitude=-112.0184807, name='Arizona Biltmore Golf Club', postal_code='85016', review_count=5, stars=3.0, state='AZ'),\n",
       " Row(address='30 Eglinton Avenue W', attributes=Row(AcceptsInsurance=None, AgesAllowed=None, Alcohol=\"u'full_bar'\", Ambience=\"{'romantic': False, 'intimate': False, 'classy': False, 'hipster': False, 'divey': False, 'touristy': False, 'trendy': False, 'upscale': False, 'casual': True}\", BYOB=None, BYOBCorkage=None, BestNights=None, BikeParking='False', BusinessAcceptsBitcoin=None, BusinessAcceptsCreditCards=None, BusinessParking=\"{'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': False}\", ByAppointmentOnly=None, Caters='True', CoatCheck=None, Corkage=None, DietaryRestrictions=None, DogsAllowed=None, DriveThru=None, GoodForDancing=None, GoodForKids='True', GoodForMeal=\"{'dessert': False, 'latenight': False, 'lunch': True, 'dinner': True, 'brunch': False, 'breakfast': False}\", HairSpecializesIn=None, HappyHour=None, HasTV='False', Music=None, NoiseLevel=\"u'loud'\", Open24Hours=None, OutdoorSeating='False', RestaurantsAttire=\"u'casual'\", RestaurantsCounterService=None, RestaurantsDelivery='False', RestaurantsGoodForGroups='True', RestaurantsPriceRange2='2', RestaurantsReservations='True', RestaurantsTableService='True', RestaurantsTakeOut='True', Smoking=None, WheelchairAccessible=None, WiFi=\"u'no'\"), business_id='QXAEGFB4oINsVuTFxEYKFQ', categories='Specialty Food, Restaurants, Dim Sum, Imported Food, Food, Chinese, Ethnic Food, Seafood', city='Mississauga', hours=Row(Friday='9:0-1:0', Monday='9:0-0:0', Saturday='9:0-1:0', Sunday='9:0-0:0', Thursday='9:0-0:0', Tuesday='9:0-0:0', Wednesday='9:0-0:0'), is_open=1, latitude=43.6054989743, longitude=-79.652288909, name='Emerald Chinese Restaurant', postal_code='L5R 3E7', review_count=128, stars=2.5, state='ON')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for null values\n",
    "# frames = [business_df, review_df, user_df]\n",
    "\n",
    "# for df in frames:\n",
    "#     for c in df.columns:\n",
    "#         null_value_count = df.where(df[c] == None).count()\n",
    "#         print('Column: {}\\nNull count: {}\\n\\n'.format(c, str(null_value_count)))\n",
    "    \n",
    "# # This is not showing any null values for the moment, remain skeptical, possible misuse of spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------+----------+----+-----+-------+--------+---------+------+-----------+------------+-----+-----+\n",
      "|address|attributes|business_id|categories|city|hours|is_open|latitude|longitude|  name|postal_code|review_count|stars|state|\n",
      "+-------+----------+-----------+----------+----+-----+-------+--------+---------+------+-----------+------------+-----+-----+\n",
      "| 151977|     67875|     192609|     93385|1204|51566|      2|  155162|   150404|145046|      17541|        1184|    9|   36|\n",
      "+-------+----------+-----------+----------+----+-----+-------+--------+---------+------+-----------+------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count of distinct values for all fields in review_df:\n",
    "this = business_df.agg(*(countDistinct(col(c)).alias(c) for c in business_df.columns))\n",
    "this.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+-------+-----+---------+-----+-------+------+-------+\n",
      "|business_id|cool|   date|funny|review_id|stars|   text|useful|user_id|\n",
      "+-----------+----+-------+-----+---------+-----+-------+------+-------+\n",
      "|     192606| 201|6552820|  231|  6685900|    5|6668738|   289|1637138|\n",
      "+-----------+----+-------+-----+---------+-----+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "this = review_df.agg(*(countDistinct(col(c)).alias(c) for c in review_df.columns))\n",
    "this.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsubset_df = business_df.filter((business_df.categories.like('%Restaurants%')) &\n",
    "                                (business_df.state == 'AZ')                               \n",
    "                               )\n",
    "print('There are {} Arizona restaurants in the dataset.'.format(bsubset_df.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major Metros in Dataset\n",
    "#### Las Vegas\n",
    "* Henderson\n",
    "#### Toronto\n",
    "* Missassauga\n",
    "* Markham\n",
    "* North York\n",
    "#### Phoenix - 56,686\n",
    "* Mesa\n",
    "* Tempe\n",
    "* Scottsdale\n",
    "* Chandler\n",
    "* Glendale\n",
    "* Gilbert\n",
    "* Peoria\n",
    "* Surprise\n",
    "#### Calgary\n",
    "#### Pittsburgh\n",
    "#### Montreal\n",
    "#### Cleveland\n",
    "#### Madison, WI\n",
    "#### Champaign, IL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which region should we select for proceeding with this study? \n",
    "\n",
    "Let's look at the densities to decide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_region_density(state, businesses, bus_reviews):\n",
    "    num_businesses = businesses.filter((businesses.categories.like('%Restaurants%')) &\n",
    "                                (business_df.state == state)).count()\n",
    "    num_reviews = bus_reviews.filter((bus_reviews.categories.like('%Restaurants%')) &\n",
    "                                (bus_reviews.state == state)).count()\n",
    "    return num_reviews/num_businesses\n",
    "\n",
    "def compare_region_densities(regions, businesses, bus_reviews):\n",
    "    max_density = 0\n",
    "    density_dict = {}\n",
    "    for region in regions:\n",
    "        density = calculate_region_density(region, businesses, bus_reviews)\n",
    "        density_dict[region] = density\n",
    "        if density > max_density:\n",
    "            max_density = density\n",
    "            max_region = region\n",
    "\n",
    "    print('Best Region: {}\\nBest Density: {}'.format(max_region, max_density))\n",
    "    return density_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['AZ', 'ON', 'NC', 'AB', 'NV', 'OH', 'PA', 'IL', 'SC', 'QC']\n",
    "\n",
    "density_dict = compare_region_densities(regions, business_df, bus_review_df)\n",
    "\n",
    "pd.DataFrame.from_dict(density_dict, orient = 'index').sort_values(0, ascending = False).plot.bar(legend = False, figsize = (10, 6))\n",
    "plt.ylabel('Review Density')\n",
    "plt.xlabel('Region')\n",
    "plt.title('Review Density by Region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The winner: Arizona\n",
    "\n",
    "We are proceeding with Arizona based businesses for this case study. Although Nevada has a greater density of reviews/restaurant, this data scientist considers it to be an anomaly in the restaurant space as well as user space given the impact tourism would have on restaurant visits/reviews. Arizona has the next highest density, would be expected to include a healthy mix of resident and non-resident reviews, most reviews are concentrated around Phoenix, and we would expect Phoenix to have a diverse group of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query for reviews of restaurants in Arizona and then convert to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make \"star\" columns unique on business_df and review_df to avoid confusion\n",
    "business_df = business_df.withColumnRenamed(\"stars\",\"avg_stars\")\n",
    "review_df = review_df.withColumnRenamed(\"stars\",\"review_stars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter business_df down to only businesses in Arizona\n",
    "business_df = business_df.filter((business_df.state == 'AZ') &\n",
    "                                (business_df.categories.like('%Restaurants%'))\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join business and review df's \n",
    "bus_review_df = review_df.join(business_df, review_df.business_id == business_df.business_id, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to pandas to make it easier to work\n",
    "# bus_review_df = bus_review_df.select(\"*\").toPandas()\n",
    "\n",
    "# # Not Currently working on my machine, getting EC2 instance ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the distribution of ratings per restaurant and ratings per user?\n",
    "ratings_per_restaurant = bus_review_df.groupBy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Troubleshoot query errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = pd.read_json('data/business.json', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop messy/unneeded columns\n",
    "col_drop = ['attributes', 'hours', 'review_count', 'postal_code']\n",
    "business_df.drop(columns = col_drop, inplace = True)\n",
    "# drop messy rows\n",
    "business_df = business_df[~business_df.categories.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query down to restaurants in AZ\n",
    "business_df = business_df[business_df.categories.str.contains('Restaurants')]\n",
    "business_df = business_df[business_df.state == 'AZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11465 entries, 11 to 192532\n",
      "Data columns (total 10 columns):\n",
      "address        11465 non-null object\n",
      "business_id    11465 non-null object\n",
      "categories     11465 non-null object\n",
      "city           11465 non-null object\n",
      "is_open        11465 non-null int64\n",
      "latitude       11465 non-null float64\n",
      "longitude      11465 non-null float64\n",
      "name           11465 non-null object\n",
      "stars          11465 non-null float64\n",
      "state          11465 non-null object\n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 985.3+ KB\n"
     ]
    }
   ],
   "source": [
    "business_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_review_df = pd.merge(sample_df, business_df, \n",
    "                         on='business_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with chunksize on pandas read_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pd.read_json('data/review.json', lines = True, chunksize = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, chunk in enumerate(reader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore modeling with small subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_json('data/review_sample.json', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_json('data/review_sample.json', lines = True)\n",
    "sample_df.drop(columns = ['cool', 'date', 'review_id',\n",
    "                        'funny', 'text', 'useful'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      "business_id    5000 non-null object\n",
      "stars          5000 non-null int64\n",
      "user_id        5000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "sample_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sample_df['stars']\n",
    "X = sample_df.drop('stars', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "identifier_df_train = X_train[['user_id', 'business_id']]\n",
    "identifier_df_test = X_test[['user_id', 'business_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "all_ratings = []\n",
    "# Iterate over all algorithms\n",
    "for algorithm in [SVD(), surprise.SlopeOne(), surprise.NMF(), surprise.NormalPredictor(), surprise.KNNBaseline(), surprise.KNNBasic(), surprise.KNNWithMeans(), surprise.KNNWithZScore(), surprise.BaselineOnly(), surprise.CoClustering()]:\n",
    "    # fit the model\n",
    "    alg_name = str(algorithm)[str(algorithm).find('ization')+8 : str(algorithm).find('obj')-1]\n",
    "    print('Fitting algorithm {}'.format(alg_name))\n",
    "    algorithm.fit(train_set)\n",
    "\n",
    "    # run predictions over\n",
    "    print('Predicting algorithm {}'.format(alg_name))\n",
    "    model_predictions = []\n",
    "    model_ratings = []\n",
    "    for idx, row in X_test.iterrows():\n",
    "        prediction = algorithm.predict(row[0], row[1])\n",
    "        model_predictions.append(prediction)\n",
    "        model_ratings.append(prediction[3])\n",
    "    \n",
    "    pred_pkl_file = alg_name + '_predictions.pkl'\n",
    "    ratings_pkl_file = alg_name + '_ratings.pkl'\n",
    "    pickle.dump(model_predictions, open(pred_pkl_file, 'wb'))\n",
    "    pickle.dump(model_ratings, open(ratings_pkl_file, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
